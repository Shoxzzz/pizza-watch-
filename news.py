import feedparser
import csv
import os
from datetime import datetime
import pytz

# ğŸ¯ ç›®æ ‡ï¼šGoogle News å®æ—¶èšåˆ (å…³é”®è¯ï¼šPentagon)
RSS_URL = "https://news.google.com/rss/search?q=Pentagon+US+Defense&hl=en-US&gl=US&ceid=US:en"
CSV_FILE = 'pentagon_news.csv'
TZ = pytz.timezone('America/New_York')

def fetch_news():
    print("ğŸ“¡ Scanning Pentagon Frequencies...")
    feed = feedparser.parse(RSS_URL)
    
    news_items = []
    
    # åªå–æœ€æ–°çš„ 10 æ¡
    for entry in feed.entries[:10]:
        try:
            # æ¸…æ´—æ ‡é¢˜ (å»æ‰ ' - Source' åç¼€)
            title = entry.title.split(' - ')[0]
            source = entry.source.title if 'source' in entry else 'Unknown'
            link = entry.link
            
            # å¤„ç†æ—¶é—´
            if hasattr(entry, 'published_parsed'):
                # æŠŠ UTC è½¬æ¢æˆç¾ä¸œæ—¶é—´
                dt = datetime(*entry.published_parsed[:6], tzinfo=pytz.utc)
                local_dt = dt.astimezone(TZ)
                time_str = local_dt.strftime('%H:%M')
                date_str = local_dt.strftime('%Y-%m-%d')
            else:
                time_str = datetime.now(TZ).strftime('%H:%M')
                date_str = datetime.now(TZ).strftime('%Y-%m-%d')

            news_items.append([date_str, time_str, source, title, link])
            print(f"âœ… Found: {title[:30]}...")
            
        except Exception as e:
            print(f"âš ï¸ Skip: {e}")
            continue

    # ğŸ’¾ æš´åŠ›è¦†ç›–å†™å…¥ (æ–°é—»æˆ‘ä»¬è¦çœ‹æœ€æ–°çš„ï¼Œä¸éœ€è¦å­˜å†å²)
    with open(CSV_FILE, 'w', newline='', encoding='utf-8-sig') as f:
        writer = csv.writer(f)
        writer.writerow(['Date', 'Time', 'Source', 'Title', 'Link'])
        writer.writerows(news_items)
    
    print("ğŸ’¾ Intel Saved to pentagon_news.csv")

if __name__ == "__main__":
    fetch_news()
